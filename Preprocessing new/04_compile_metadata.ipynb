{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author : Sapna Mishra\n",
    "##### Project : Determining the Aggressiveness of Cancer using mpMRI Scans\n",
    "##### Last Modified: 7th Oct 2020\n",
    "##### Task: Compiling the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cases_meta_df(is_training_data,sequence_type):\n",
    "    \"\"\"\n",
    "    This function generates a data frame containing the necessary information (ProxID, DCMSerDesc,\n",
    "    and path to resampled NIFTI file) for cases so that they can be joined to tabular information \n",
    "    provided by the research team. Data that will be merged with dataset are found in ProstateX-Images\n",
    "    and ProstateX-Images-KTrans files (Train and Test Respectively) \n",
    "    \"\"\"\n",
    "\n",
    "    if is_training_data:\n",
    "        path_lesion_information = 'C:/Sapna/Graham/Capstone/data/train/lesion_info'\n",
    "        path_resampled_nifti = 'C:/Sapna/Graham/Capstone/data/train/generated/nrrd'\n",
    "    else:\n",
    "        path_lesion_information = 'C:/Sapna/Graham/Capstone/data/test/lesion_info'\n",
    "        path_resampled_nifti = 'C:/Sapna/Graham/Capstone/data/test/generated/nrrd'\n",
    "    \n",
    "    patient_data = {}\n",
    "    for f1, filename1 in enumerate(os.listdir(path_resampled_nifti)):\n",
    "        if filename1 == sequence_type:\n",
    "            for f2, filename2 in enumerate(os.listdir(str(Path(path_resampled_nifti))+'/'+ filename1)):     \n",
    "\n",
    "                split = filename2.split('.')\n",
    "                constructed_DCMSerDescr = split[0]\n",
    "\n",
    "                path_to_resampled = str(path_resampled_nifti) + str(\"/\") + sequence_type + str(\"/\") + str(filename2) \n",
    "\n",
    "                if 'tse_sag' in constructed_DCMSerDescr:          \n",
    "                    sequence_type = 'tse_sag'\n",
    "                    name1 = constructed_DCMSerDescr[15:]\n",
    "                    constructed_DCMSerDescr = name1[:10]\n",
    "\n",
    "                elif 'tse_tra' in constructed_DCMSerDescr:            \n",
    "                    sequence_type = 'tse_tra'\n",
    "                    name1 = constructed_DCMSerDescr[15:]\n",
    "                    constructed_DCMSerDescr = name1[:10]       \n",
    "\n",
    "                elif 'ADC' in constructed_DCMSerDescr:         \n",
    "                    sequence_type = 'adc'\n",
    "                    name1 = constructed_DCMSerDescr[15:]  \n",
    "                    name2 = name1.rsplit(\"_\",1)\n",
    "                    constructed_DCMSerDescr = name2[0]\n",
    "\n",
    "                elif 'BVAL' in constructed_DCMSerDescr:          \n",
    "                    sequence_type = 'bval'\n",
    "                    name1 = constructed_DCMSerDescr[15:]  \n",
    "                    name2 = name1.rsplit(\"_\",1)\n",
    "                    constructed_DCMSerDescr = name2[0]\n",
    "\n",
    "                elif 'Ktrans' in constructed_DCMSerDescr:         \n",
    "                    sequence_type = 'ktrans'\n",
    "                    constructed_DCMSerDescr = constructed_DCMSerDescr \n",
    "\n",
    "                else:\n",
    "                    print(\"Sequence type is incorrect\")\n",
    "\n",
    "                patient_id = filename2[0:14]\n",
    "                key = patient_id\n",
    "                value = [constructed_DCMSerDescr, path_to_resampled, sequence_type]\n",
    "                patient_data[key] = value\n",
    "        \n",
    "    cases_meta_data_df = pd.DataFrame.from_dict(patient_data, orient = 'index')\n",
    "    cases_meta_data_df = cases_meta_data_df.reset_index()\n",
    "    cases_meta_data_df.columns = ['ProxID', 'DCMSerDescr', 'resampled_nifti', 'sequence_type']\n",
    "    \n",
    "    return cases_meta_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(is_training_data, sequence_df_array):\n",
    "    \"\"\"\n",
    "    This function combines information provided by the research team in ProstateX-Images\n",
    "    and ProstateX-Images-KTrans (Train/Test) files with paths to the resampled NIFTI files. \n",
    "    The function accepts a boolean is_training_data to determine if it is training or test\n",
    "    data that needs to be processed. A list containing data frames of the joined data\n",
    "    is the second parameter. The function concatenates the data frames in this list and\n",
    "    returns a final data frame of all the data.\n",
    "    \"\"\"\n",
    "\n",
    "    if is_training_data:\n",
    "        prostateX_images = pd.read_csv('C:/Sapna/Graham/Capstone/data/train/lesion_info/ProstateX-2-Images-Train.csv')\n",
    "        prostateX_images_ktrans = pd.read_csv('C:/Sapna/Graham/Capstone/data/train/lesion_info/ProstateX-2-Images-KTrans-Train-V1.csv')\n",
    "        prostateX_findings = pd.read_csv('C:/Sapna/Graham/Capstone/data/train/lesion_info/ProstateX-2-Findings-Train.csv')\n",
    "    else:\n",
    "        prostateX_images = pd.read_csv('C:/Sapna/Graham/Capstone/data/test/lesion_info/ProstateX-2-Images-Test.csv')\n",
    "        prostateX_images_ktrans = pd.read_csv('C:/Sapna/Graham/Capstone/data/test/lesion_info/ProstateX-2-Images-KTrans-Test_V1.csv')\n",
    "        prostateX_findings = pd.read_csv('C:/Sapna/Graham/Capstone/data/test/lesion_info/ProstateX-2-Findings-Test.csv')\n",
    "  \n",
    "    df_collection = []\n",
    "    \n",
    "    # Merging info for the DICOM series\n",
    "    for dataframe in sequence_df_array[0:6]:\n",
    "        # Convert DCMSerDescr values to lowercase in both frames (sanitize)\n",
    "        dataframe.loc[:,'DCMSerDescr'] = dataframe.loc[:,'DCMSerDescr'].apply(lambda x: x.lower())\n",
    "        prostateX_images.loc[:,'DCMSerDescr'] = prostateX_images.loc[:,'DCMSerDescr'].apply(lambda x: x.lower())\n",
    "        \n",
    "        # Keep only important columns from researcher provided data\n",
    "        prostateX_images = prostateX_images[['ProxID', 'DCMSerDescr', 'fid', 'pos','WorldMatrix', 'ijk']]\n",
    "\n",
    "        # Merge NIFTI paths with researcher provided data\n",
    "        first_merge = pd.merge(dataframe, prostateX_images, how = 'inner', on = ['ProxID', 'DCMSerDescr'])\n",
    "        \n",
    "        # Merge findings (cancer/not cancer)\n",
    "        final_merge = pd.merge(first_merge, prostateX_findings, how = 'inner', on = ['ProxID', 'fid', 'pos'])\n",
    "        df_collection.append(final_merge)\n",
    "    \n",
    "   \n",
    "    # Merging info for the KTRANS series\n",
    "    first_merge = pd.merge(dataframe, prostateX_images_ktrans, how = 'inner', on = ['ProxID'])\n",
    "    \n",
    "    # Merge findings (G)\n",
    "    final_merge = pd.merge(first_merge, prostateX_findings, how = 'inner', on = ['ProxID', 'fid', 'pos'])\n",
    "    df_collection.append(final_merge)\n",
    "\n",
    "    final_dataframe = pd.concat(df_collection, ignore_index=True)\n",
    "\n",
    "    return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_values(is_training_data, dataframe):\n",
    "    \"\"\"\n",
    "    This function accepts a data frame and reformats entries in select columns\n",
    "    to make them more acceptable for use in patch analysis (i.e. converting strings of \n",
    "    coordinate values to tuples of float).\n",
    "    \"\"\"\n",
    "\n",
    "    def convert_to_tuple(dataframe, column):\n",
    "        \"\"\"\n",
    "        This function converts row values (represented as string of floats\n",
    "        delimited by spaces) to a tuple of floats. It accepts the original data\n",
    "        frame and a string for the specified column that needs to be converted.\n",
    "        \"\"\"  \n",
    "        pd_series_containing_lists_of_strings = dataframe[column].str.split() \n",
    "        list_for_new_series = []\n",
    "        for list_of_strings in pd_series_containing_lists_of_strings:\n",
    "            container_list = []\n",
    "            for item in list_of_strings:\n",
    "                if column == 'pos':\n",
    "                    container_list.append(float(item))\n",
    "                else:\n",
    "                    container_list.append(int(item))\n",
    "            list_for_new_series.append(tuple(container_list))\n",
    "        \n",
    "        return pd.Series(list_for_new_series)    \n",
    "\n",
    "    # Call function to convert select columns\n",
    "    dataframe = dataframe.assign(pos_tuple = convert_to_tuple(dataframe, 'pos'))\n",
    "    dataframe = dataframe.assign(ijk_tuple = convert_to_tuple(dataframe, 'ijk'))\n",
    "    \n",
    "    # Drop old columns, rename new ones, and reorder...\n",
    "    dataframe = dataframe.drop(columns = ['pos','ijk', 'WorldMatrix'])\n",
    "    dataframe = dataframe.rename(columns = {'pos_tuple':'pos', 'ijk_tuple':'ijk'})\n",
    "\n",
    "    if is_training_data:\n",
    "        repaired_df = dataframe.loc[:,['ProxID', 'DCMSerDescr', 'resampled_nifti', 'sequence_type', 'fid', 'pos', 'ijk', 'zone', 'ggg']]\n",
    "    else:\n",
    "        repaired_df = dataframe.loc[:,['ProxID', 'DCMSerDescr', 'resampled_nifti', 'sequence_type', 'fid', 'pos', 'ijk', 'zone']]\n",
    "    \n",
    "    return repaired_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_directory(is_training_data, dataframe):\n",
    "    if is_training_data:\n",
    "        dataframe.to_csv('C:/Sapna/Graham/Capstone/data/train/generated/dataframes/training_meta_data.csv')\n",
    "        dataframe.to_pickle('C:/Sapna/Graham/Capstone/data/train/generated/dataframes/training_meta_data.pkl')\n",
    "    else:\n",
    "        dataframe.to_csv('C:/Sapna/Graham/Capstone/data/test/generated/dataframes/test_meta_data.csv')\n",
    "        dataframe.to_pickle('C:/Sapna/Graham/Capstone/data/test/generated/dataframes/test_meta_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset are you working with? (1-Train; 2-Test):2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    is_training_data = False\n",
    "    dataset_type = input('Which dataset are you working with? (1-Train; 2-Test):')\n",
    "    if dataset_type == str(1):\n",
    "        is_training_data = True\n",
    "    \n",
    "    t2_tse_tra_meta = generate_cases_meta_df(is_training_data, 'tse_tra')\n",
    "    t2_tse_sag_meta = generate_cases_meta_df(is_training_data, 'tse_sag')\n",
    "    adc_meta = generate_cases_meta_df(is_training_data, 'adc')\n",
    "    bval_meta = generate_cases_meta_df(is_training_data, 'bval')\n",
    "    ktrans_meta = generate_cases_meta_df(is_training_data, 'ktrans')\n",
    "\n",
    "    sequence_df_array = [t2_tse_tra_meta, t2_tse_sag_meta , adc_meta, bval_meta, ktrans_meta]\n",
    "    \n",
    "    complete_df = join_data(is_training_data, sequence_df_array)\n",
    "    final_df = repair_values(is_training_data, complete_df)\n",
    "    \n",
    "    final_dataframe_deduplicated = final_df.drop_duplicates(subset=['ProxID','sequence_type', 'pos'], keep = 'first')\n",
    "    save_data_to_directory(is_training_data, final_dataframe_deduplicated)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
