{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Author : Sapna Mishra\n",
    "##### Project : Determining the Aggressiveness of Cancer using mpMRI Scans\n",
    "##### Last Modified: 8th Oct 2020\n",
    "##### Task:- Region of Interest Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhavy\\anaconda3\\lib\\site-packages\\dicom\\__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from scipy import ndimage\n",
    "from skimage import exposure\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.testing import data_path\n",
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, IntSlider, ToggleButtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cases = []\n",
    "\n",
    "def generate_patches(row, patch_sizes):\n",
    " \n",
    "    path_to_resampled_file = row.resampled_nifti\n",
    "    reported_pos = row.pos\n",
    "\n",
    "    if 'tse_tra' in row.DCMSerDescr:\n",
    "        patch_size = patch_sizes.get('tse_tra')\n",
    "    elif 'adc' in row.DCMSerDescr:\n",
    "        patch_size = patch_sizes.get('adc')\n",
    "    elif 'bval' in row.DCMSerDescr:\n",
    "        patch_size = patch_sizes.get('bval')\n",
    "    elif 'ktrans' in row.DCMSerDescr:\n",
    "        patch_size = patch_sizes.get('ktrans')\n",
    "    else:\n",
    "        print(\"Incorrect Sequence Name\")\n",
    "\n",
    "    def load_image(path_to_resampled_file):\n",
    "        \n",
    "        sitk_image = sitk.ReadImage(str(path_to_resampled_file))\n",
    "        image_array = sitk.GetArrayViewFromImage(sitk_image)\n",
    "        \n",
    "        return sitk_image, image_array\n",
    "    \n",
    "    def calculate_location_of_finding(sitk_image, reported_pos):\n",
    "        location_of_finding = sitk_image.TransformPhysicalPointToIndex(reported_pos)\n",
    "        return location_of_finding\n",
    "\n",
    "    def equalize_image(image_array):\n",
    "        equalized_image_array = exposure.equalize_hist(image_array)\n",
    "        return equalized_image_array\n",
    "    \n",
    "    def extract_patch(image_array, location_of_finding, patch_size):\n",
    "        x = location_of_finding[0]\n",
    "        y = location_of_finding[1]\n",
    "\n",
    "        x_start = x - (patch_size // 2)\n",
    "        x_end = x + (patch_size // 2)\n",
    "        y_start = y - (patch_size // 2)\n",
    "        y_end = y + (patch_size // 2)\n",
    "\n",
    "        try:\n",
    "            extracted_patch = image_array[location_of_finding[2], y_start:y_end, x_start:x_end]\n",
    "        except IndexError:\n",
    "            extracted_patch = image_array[-1, y_start:y_end, x_start:x_end]\n",
    "            problem_cases.append(row.ProxID)\n",
    "            problem_cases.append(row.DCMSerDescr)\n",
    "            print('Problem with image:', row.ProxID, path_to_resampled_file)\n",
    "            pass \n",
    "\n",
    "        return extracted_patch\n",
    "    \n",
    "    def generate_rotations(image_array):\n",
    "        patch_45 = ndimage.rotate(image_array, 45, reshape=False)\n",
    "        patch_90 = ndimage.rotate(image_array, 90, reshape=False)\n",
    "        patch_180 = ndimage.rotate(image_array, 180, reshape=False)\n",
    "        patch_270 = ndimage.rotate(image_array, 270, reshape=False)\n",
    "        return (patch_45, patch_90, patch_180, patch_270)\n",
    "    \n",
    "    def rescale_intensities_of_patch(patch): \n",
    "        scaler = MinMaxScaler(feature_range = (0,1)).fit(patch)\n",
    "        rescaled_patch = scaler.transform(patch)\n",
    "        return rescaled_patch\n",
    "\n",
    "    sitk_image, image_array = load_image(path_to_resampled_file)\n",
    "    location_of_finding = calculate_location_of_finding(sitk_image, reported_pos)\n",
    "    \n",
    "    raw_image_array = image_array.copy()\n",
    "    equalized_image_array = equalize_image(image_array)\n",
    "      \n",
    "    patch = extract_patch(raw_image_array, location_of_finding, patch_size)\n",
    "    eq_patch = extract_patch(equalized_image_array, location_of_finding, patch_size)\n",
    "    \n",
    "#     eq_45 = generate_rotations(eq_patch)[0]\n",
    "#     eq_90 = generate_rotations(eq_patch)[1]\n",
    "#     eq_180 = generate_rotations(eq_patch)[2]\n",
    "#     eq_270 = generate_rotations(eq_patch)[3]\n",
    "\n",
    "#     patch_01 = rescale_intensities_of_patch(patch)\n",
    "#     eq_patch_01 = rescale_intensities_of_patch(eq_patch)\n",
    "#     eq_45_01 = rescale_intensities_of_patch(eq_45)\n",
    "#     eq_90_01 = rescale_intensities_of_patch(eq_90)\n",
    "#     eq_180_01 = rescale_intensities_of_patch(eq_180)\n",
    "#     eq_270_01 = rescale_intensities_of_patch(eq_270)\n",
    "    \n",
    "#     patch_values = pd.Series({'patch':patch_01, 'eq_patch':eq_patch_01, 'eq_45':eq_45_01, 'eq_90':eq_90_01, 'eq_180':eq_180_01, 'eq_270':eq_270_01})\n",
    "    patch_values = pd.Series({'patch':eq_patch})\n",
    "\n",
    "    return patch_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_patch_columns_to_df(dataframe, patch_sizes):\n",
    "    new_data = dataframe.apply(generate_patches, patch_sizes = patch_sizes, axis = 1)\n",
    "    merged_frame = pd.concat([dataframe, new_data], axis=1)\n",
    "    return merged_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_problem_cases(dataframe, problem_cases):\n",
    "    problem_cases = set(problem_cases)\n",
    "    to_delete = []\n",
    "    for row_id, row in dataframe.iterrows():\n",
    "        if (row.ProxID in problem_cases) and (row.DCMSerDescr in problem_cases):\n",
    "            to_delete.append(row.ProxID)\n",
    "    clean_dataframe = dataframe[~dataframe['ProxID'].isin(set(to_delete))]\n",
    "    return clean_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_data(is_training_data, dataframe):\n",
    "    if is_training_data:\n",
    "        dataframe.to_csv('C:/Sapna/Graham/Capstone/data/train/generated/dataframes/training.csv')\n",
    "        dataframe.to_pickle('C:/Sapna/Graham/Capstone/data/train/generated/dataframes/training.pkl')\n",
    "    else:\n",
    "        dataframe.to_csv('C:/Sapna/Graham/Capstone/data/test/generated/dataframes/testing.csv')\n",
    "        dataframe.to_pickle('C:/Sapna/Graham/Capstone/data/test/generated/dataframes/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which dataset are you working with? (1-Train; 2-Test):1\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    is_training_data = False\n",
    "    dataset_type = input('Which dataset are you working with? (1-Train; 2-Test):')\n",
    "    if dataset_type == str(1):\n",
    "        is_training_data = True\n",
    "\n",
    "    patch_sizes = {\n",
    "        'tse_tra': 64,\n",
    "        'tse_sag': 32,\n",
    "        'adc': 32,\n",
    "        'bval':32,\n",
    "        'ktrans':8\n",
    "    }\n",
    "    \n",
    "    if is_training_data:\n",
    "        dataset = pd.read_pickle('C:/Sapna/Graham/Capstone/data/train/generated/dataframes/training_meta_data.pkl')\n",
    "        dataset= dataset[dataset[\"sequence_type\"]!=\"tse_sag\"]\n",
    "        complete_dataset = add_patch_columns_to_df(dataset, patch_sizes)\n",
    "        clean_dataset = remove_problem_cases(complete_dataset, problem_cases)\n",
    "        persist_data(is_training_data, clean_dataset)\n",
    "    else:\n",
    "        dataset = pd.read_pickle('C:/Sapna/Graham/Capstone/data/test/generated/dataframes/test_meta_data.pkl')\n",
    "        dataset= dataset[dataset[\"sequence_type\"]!=\"tse_sag\"]\n",
    "        complete_dataset = add_patch_columns_to_df(dataset, patch_sizes)\n",
    "        clean_dataset = remove_problem_cases(complete_dataset, problem_cases)\n",
    "        persist_data(is_training_data, clean_dataset)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
